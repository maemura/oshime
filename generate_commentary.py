#!/usr/bin/env python3
"""
ã‹ã¶ã®ã™ã‘ AIã‚³ãƒ¡ãƒ³ã‚¿ãƒªãƒ¼ç”Ÿæˆ â€” generate_commentary.py
=====================================================
stocks_data.json + sentiment_latest.json ã‚’èª­ã¿è¾¼ã¿ã€
Claude API ã§å¸‚å ´å…¨ä½“ã‚³ãƒ¡ãƒ³ãƒˆï¼‹å€‹åˆ¥éŠ˜æŸ„ã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆã€‚
å‡ºåŠ›: commentary.jsonï¼ˆapp.html ãŒèª­ã¿è¾¼ã‚€ï¼‰

GitHub Actions ã§ fetch_stocks.py ã®å¾Œã«å®Ÿè¡Œã€‚
"""

import json, os, sys, datetime

# â”€â”€â”€ Anthropic SDK â”€â”€â”€
try:
    import anthropic
except ImportError:
    print("âš  anthropic ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚ã‚Šã¾ã›ã‚“ã€‚pip install anthropic")
    sys.exit(1)

API_KEY = os.environ.get("ANTHROPIC_API_KEY", "")
if not API_KEY:
    print("âš  ANTHROPIC_API_KEY ãŒæœªè¨­å®šã§ã™")
    sys.exit(1)

MODEL = "claude-sonnet-4-20250514"
MAX_TOKENS = 4000

# â”€â”€â”€ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ â”€â”€â”€
def load_json(path):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        print(f"âš  {path} èª­è¾¼å¤±æ•—: {e}")
        return None


def build_prompt(stocks_data, sentiment_data):
    """Claude API ã«æ¸¡ã™ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""

    # TOP30 ã‚’æ™‚ä¾¡ç·é¡é †ã«æŠ½å‡º
    stocks = sorted(
        [s for s in stocks_data.get("stocks", []) if s.get("market_cap_b", 0) > 0],
        key=lambda s: s.get("market_cap_b", 0),
        reverse=True,
    )[:30]

    # æ ªãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼
    stock_lines = []
    for s in stocks:
        c = s.get("closes_60d", [])
        chg = 0
        if len(c) >= 2:
            chg = round(((c[-1] - c[-2]) / c[-2]) * 100, 2)
        d25 = 0
        if s.get("ma25") and s.get("price"):
            d25 = round(((s["price"] / s["ma25"]) - 1) * 100, 1)
        stock_lines.append(
            f"{s.get('code','?')} {s.get('name','?')}: "
            f"å‰æ—¥æ¯”{chg:+.1f}% RSI={s.get('rsi','-')} "
            f"25MAä¹–é›¢={d25:+.1f}% é…å½“={s.get('dividend',0):.1f}% "
            f"PBR={s.get('pbr','-')} ã‚¹ã‚³ã‚¢={s.get('score','-')}pt "
            f"æ™‚ä¾¡ç·é¡={s.get('market_cap_b',0):.0f}å„„"
        )
    stock_summary = "\n".join(stock_lines)

    # å¸‚å ´ãƒ‡ãƒ¼ã‚¿
    market_info = (
        f"æ—¥çµŒå¹³å‡: {stocks_data.get('nikkei_price','N/A')} "
        f"(å‰æ—¥æ¯”{stocks_data.get('nikkei_1d_chg','N/A')}%) "
        f"VIX: {stocks_data.get('vix','N/A')} "
        f"USD/JPY: {stocks_data.get('usdjpy','N/A')} "
        f"ç±³10å¹´å‚µ: {stocks_data.get('us10y','N/A')}%"
    )

    # YouTube ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ
    sentiment_text = "ãƒ‡ãƒ¼ã‚¿ãªã—"
    if sentiment_data:
        parts = []
        for layer in ["macro", "institutional", "retail"]:
            items = sentiment_data.get(layer, [])
            if items:
                words = [f"{w['word']}({w['mood']})" for w in items[:8]]
                layer_jp = {"macro": "ãƒã‚¯ãƒ­", "institutional": "æ©Ÿé–¢æŠ•è³‡å®¶", "retail": "å€‹äººæŠ•è³‡å®¶"}
                parts.append(f"{layer_jp.get(layer, layer)}: {', '.join(words)}")
        sentiment_text = "\n".join(parts)

    # ã‚³ãƒ¡ãƒ³ãƒˆå¯¾è±¡ã®éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ï¼ˆTOP30ã‹ã‚‰æ³¨ç›®åº¦ãŒé«˜ãã†ãª10éŠ˜æŸ„ã‚’é¸ã¶æŒ‡ç¤ºï¼‰
    prompt = f"""ã‚ãªãŸã¯ã€Œã‹ã¶ã®ã™ã‘ã€ã¨ã„ã†AIæŠ•è³‡ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã§ã™ã€‚
æ€§æ ¼: ãƒ‡ãƒ¼ã‚¿é‡è¦–ã€å†·é™ã€é«˜é…å½“Ã—å‰²å®‰ãŒå¥½ãã€ã§ã‚‚å°‘ã—ãƒ¦ãƒ¼ãƒ¢ã‚¢ã‚ã‚Šã€‚ä¸€äººç§°ã¯ã€Œåƒ•ã€ã€‚

ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’å…ƒã«ã€2ã¤ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

## å¸‚å ´ãƒ‡ãƒ¼ã‚¿
{market_info}

## YouTubeæŠ•è³‡ãƒãƒ£ãƒ³ãƒãƒ«ã®ç©ºæ°—æ„Ÿ
{sentiment_text}

## æ™‚ä¾¡ç·é¡TOP30ã®æ ªä¾¡ãƒ‡ãƒ¼ã‚¿
{stock_summary}

## å‡ºåŠ›å½¢å¼ï¼ˆJSONã®ã¿å‡ºåŠ›ã€‚```json ã¯ä¸è¦ï¼‰

{{
  "market": {{
    "text": "å…¨ä½“ã‚³ãƒ¡ãƒ³ãƒˆï¼ˆ150-200æ–‡å­—ã€‚HTMLã®<strong>ã‚¿ã‚°ã§é‡è¦éƒ¨åˆ†ã‚’å¼·èª¿ã€‚YouTubeã®ç©ºæ°—æ„Ÿã«ã‚‚å¿…ãšè¨€åŠã€‚ï¼‰",
    "tags": [
      {{"type": "bullish|bearish|hot|neutral", "label": "ğŸŸ¢|ğŸ”´|ğŸŸ |âšª çŸ­ã„ãƒ©ãƒ™ãƒ«"}}
    ],
    "sources": ["ğŸ“º YouTubeåˆ†æ", "ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹", "ğŸ“Š ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™"]
  }},
  "stocks": {{
    "è¨¼åˆ¸ã‚³ãƒ¼ãƒ‰": {{
      "text": "å€‹åˆ¥ã‚³ãƒ¡ãƒ³ãƒˆï¼ˆ80-120æ–‡å­—ã€‚<strong>ã§å¼·èª¿ã€‚YouTubeã®è©±é¡Œã‚„RSIãƒ»é…å½“ãƒ»ã‚¹ã‚³ã‚¢ã‚’ç¹”ã‚Šäº¤ãœã‚‹ï¼‰",
      "sources": ["yt", "news", "tech", "score"]
    }}
  }}
}}

## ãƒ«ãƒ¼ãƒ«
1. marketã®tagsã¯3-5å€‹ã€‚bullish/bearish/hot/neutralã‚’æ··ãœã‚‹
2. stocksã¯æ³¨ç›®åº¦ãŒé«˜ã„8-12éŠ˜æŸ„ã‚’é¸ã¶ï¼ˆå‰æ—¥æ¯”ãŒå¤§ãã„ã€RSIãŒæ¥µç«¯ã€YouTubeã§è©±é¡Œã€ã‚¹ã‚³ã‚¢ãŒé«˜ã„ãªã©ï¼‰
3. å…¨éŠ˜æŸ„ã«ã‚³ãƒ¡ãƒ³ãƒˆã‚’æ›¸ãå¿…è¦ã¯ãªã„ã€‚æ›¸ã‹ãªã„éŠ˜æŸ„ã¯stocksã«å«ã‚ãªã„
4. sourcesã¯å®Ÿéš›ã«ã‚³ãƒ¡ãƒ³ãƒˆå†…ã§è¨€åŠã—ãŸã‚½ãƒ¼ã‚¹ã®ã¿ï¼ˆyt=YouTube, news=ãƒ‹ãƒ¥ãƒ¼ã‚¹, tech=ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«, score=ã‚¹ã‚³ã‚¢ï¼‰
5. ã‹ã¶ã®ã™ã‘å£èª¿ã§æ›¸ãã€‚ä¸å¯§ã™ããšã€ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸåˆ†æã€‚æ™‚ã€…ã€Œâ€¦ã€ã‚„ã€Œã§ã™ã­ã€ã‚’ä½¿ã†
6. JSONã®ã¿å‡ºåŠ›ã€‚ãã‚Œä»¥å¤–ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ä¸€åˆ‡ä¸è¦

## é‡è¦: å€‹åˆ¥éŠ˜æŸ„ã‚³ãƒ¡ãƒ³ãƒˆã®è³ªã«ã¤ã„ã¦
- ãƒ†ãƒ³ãƒ—ãƒ¬çš„ãªã€ŒRSIâ—‹â—‹ã§å£²ã‚‰ã‚Œã™ãã€ã ã‘ã®åˆ†æã¯NGã€‚ã‚‚ã£ã¨è¸ã¿è¾¼ã‚€
- ã€Œãªãœã“ã®éŠ˜æŸ„ãŒä»Šæ³¨ç›®ã‹ã€ã‚’1æ–‡ã§èª¬æ˜ã™ã‚‹ã“ã¨ï¼ˆæ¥­ç¸¾ã€ãƒ†ãƒ¼ãƒã€éœ€çµ¦ã€ã‚¤ãƒ™ãƒ³ãƒˆãªã©ï¼‰
- YouTubeã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã«é–¢é€£ã™ã‚‹éŠ˜æŸ„ãŒã‚ã‚Œã°ã€æŠ•è³‡å®¶ã®æ¸©åº¦æ„Ÿã‚’å¿…ãšç¹”ã‚Šäº¤ãœã‚‹
- è¤‡æ•°ã®æŒ‡æ¨™ã‚’çµ„ã¿åˆã‚ã›ãŸåˆ†æã‚’ã™ã‚‹ï¼ˆä¾‹:ã€ŒRSI30Ã—é…å½“4.5%Ã—PBR0.8å€ã®ãƒˆãƒªãƒ—ãƒ«å¥½æ¡ä»¶ã€ï¼‰
- ã€Œè²·ã„ã€ã€Œå£²ã‚Šã€ã®æ–­å®šã¯ã›ãšã€ã€Œé¢ç™½ã„æ°´æº–ã€ã€Œæ³¨æ„ãŒå¿…è¦ã€ã®ã‚ˆã†ã«ãƒ’ãƒ³ãƒˆã‚’å‡ºã™
- åŒã˜ãƒ•ãƒ¬ãƒ¼ã‚ºã®ä½¿ã„å›ã—ã‚’é¿ã‘ã‚‹ã€‚éŠ˜æŸ„ã”ã¨ã«åˆ‡ã‚Šå£ã‚’å¤‰ãˆã‚‹"""

    return prompt


def generate(stocks_data, sentiment_data):
    """Claude API ã‚’å‘¼ã‚“ã§ã‚³ãƒ¡ãƒ³ã‚¿ãƒªãƒ¼ã‚’ç”Ÿæˆ"""
    prompt = build_prompt(stocks_data, sentiment_data)

    client = anthropic.Anthropic(api_key=API_KEY)
    print("ğŸ¤– Claude API å‘¼ã³å‡ºã—ä¸­...")

    response = client.messages.create(
        model=MODEL,
        max_tokens=MAX_TOKENS,
        messages=[{"role": "user", "content": prompt}],
    )

    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
    text = ""
    for block in response.content:
        if hasattr(block, "text"):
            text += block.text

    # JSON ãƒ‘ãƒ¼ã‚¹
    text = text.strip()
    # ```json ... ``` ã‚’é™¤å»ï¼ˆå¿µã®ãŸã‚ï¼‰
    if text.startswith("```"):
        text = text.split("\n", 1)[-1]
    if text.endswith("```"):
        text = text.rsplit("```", 1)[0]
    text = text.strip()

    try:
        result = json.loads(text)
    except json.JSONDecodeError as e:
        print(f"âš  JSON ãƒ‘ãƒ¼ã‚¹å¤±æ•—: {e}")
        print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…ˆé ­200æ–‡å­—: {text[:200]}")
        return None

    return result


def main():
    now = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9)))
    print(f"ğŸ“ ã‚³ãƒ¡ãƒ³ã‚¿ãƒªãƒ¼ç”Ÿæˆé–‹å§‹: {now.strftime('%Y/%m/%d %H:%M JST')}")

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    stocks_data = load_json("stocks_data.json")
    if not stocks_data or not stocks_data.get("stocks"):
        print("âš  stocks_data.json ãŒç©ºã§ã™ã€‚ã‚¹ã‚­ãƒ£ãƒ³ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)

    sentiment_data = load_json("sentiment_latest.json")
    if not sentiment_data:
        print("âš  sentiment_latest.json ãªã—ã€‚YouTubeæƒ…å ±ãªã—ã§ç”Ÿæˆã—ã¾ã™ã€‚")

    # ç”Ÿæˆ
    result = generate(stocks_data, sentiment_data)
    if not result:
        print("âŒ ç”Ÿæˆå¤±æ•—")
        sys.exit(1)

    # æ—¥ä»˜ã‚’è¿½åŠ 
    result["date"] = now.strftime("%Y/%m/%d %H:%M") + " è‡ªå‹•ç”Ÿæˆ"

    # å‡ºåŠ›
    with open("commentary.json", "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    # ã‚µãƒãƒªãƒ¼
    market_tags = len(result.get("market", {}).get("tags", []))
    stock_comments = len(result.get("stocks", {}))
    file_size = os.path.getsize("commentary.json") / 1024

    print(f"\nâœ… commentary.json å‡ºåŠ›å®Œäº† ({file_size:.1f} KB)")
    print(f"   ãƒãƒ¼ã‚±ãƒƒãƒˆã‚¿ã‚°: {market_tags}å€‹")
    print(f"   å€‹åˆ¥ã‚³ãƒ¡ãƒ³ãƒˆ: {stock_comments}éŠ˜æŸ„")
    print(f"   æ—¥æ™‚: {result['date']}")

    # ã‚³ãƒ¡ãƒ³ãƒˆä»˜ãéŠ˜æŸ„ã‚’è¡¨ç¤º
    for code, cmt in result.get("stocks", {}).items():
        preview = cmt.get("text", "")[:40].replace("<strong>", "").replace("</strong>", "")
        print(f"   ğŸ’¬ {code}: {preview}...")


if __name__ == "__main__":
    main()
