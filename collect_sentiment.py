#!/usr/bin/env python3
"""
collect_sentiment.py - ãƒãƒ¼ã‚±ãƒƒãƒˆã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
YouTubeæ ªç³»ãƒãƒ£ãƒ³ãƒãƒ«ã®æœ€æ–°å‹•ç”»ã‹ã‚‰ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã‚’æŠ½å‡ºã—ã€
sentiment_data/YYYY-MM-DD.json ã«è“„ç©ã™ã‚‹ã€‚
"""

import os, sys, json, re
import urllib.request, urllib.parse
from datetime import datetime, timedelta
from pathlib import Path
from collections import Counter

# â”€â”€ å®šæ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CHANNELS = {
    "@SHO1112":       "Sho'sæŠ•è³‡æƒ…å ±å±€",
    "@kabureallive":  "æ ªãƒªã‚¢ãƒ«ãƒ©ã‚¤ãƒ–",
    "@higedura24":    "ã²ã’ã¥ã‚‰æ ªã¡ã‚ƒã‚“ã­ã‚‹",
    "@tradelabo2222": "ãƒˆãƒ¬ãƒ¼ãƒ‰ãƒ©ãƒœ",
    "@bacchama":      "ã°ã£ã¡ã‚ƒã¾ã®æŠ•è³‡ãƒãƒ£ãƒ³ãƒãƒ«",
    "@yutai_rider":   "å„ªå¾…ãƒ©ã‚¤ãƒ€ãƒ¼",
    "@tabbata":       "ãŸã°ãŸã®æŠ•è³‡ch",
}

MAX_AGE_DAYS = 7
SENTIMENT_DIR = Path("sentiment_data")
ANTHROPIC_API_URL = "https://api.anthropic.com/v1/messages"


def resolve_handle(api_key, handle):
    """@handle â†’ channelId"""
    params = urllib.parse.urlencode({
        "part": "id,snippet",
        "forHandle": handle.lstrip("@"),
        "key": api_key,
    })
    url = f"https://www.googleapis.com/youtube/v3/channels?{params}"
    try:
        with urllib.request.urlopen(urllib.request.Request(url), timeout=10) as resp:
            items = json.loads(resp.read().decode()).get("items", [])
            if items:
                return items[0]["id"]
    except Exception as e:
        print(f"    âš  forHandleå¤±æ•—: {e}")

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: search
    params = urllib.parse.urlencode({
        "part": "snippet", "q": handle, "type": "channel", "maxResults": 1, "key": api_key,
    })
    url = f"https://www.googleapis.com/youtube/v3/search?{params}"
    try:
        with urllib.request.urlopen(urllib.request.Request(url), timeout=10) as resp:
            items = json.loads(resp.read().decode()).get("items", [])
            if items:
                return items[0]["snippet"]["channelId"]
    except Exception as e:
        print(f"    âš  searchå¤±æ•—: {e}")
    return None


def fetch_latest_videos(api_key, channel_id, max_results=3):
    after = (datetime.utcnow() - timedelta(days=MAX_AGE_DAYS)).strftime("%Y-%m-%dT%H:%M:%SZ")
    params = urllib.parse.urlencode({
        "part": "snippet", "channelId": channel_id, "maxResults": max_results,
        "order": "date", "type": "video", "publishedAfter": after, "key": api_key,
    })
    url = f"https://www.googleapis.com/youtube/v3/search?{params}"
    try:
        with urllib.request.urlopen(urllib.request.Request(url), timeout=15) as resp:
            data = json.loads(resp.read().decode())
        return [{"video_id": i["id"]["videoId"], "title": i["snippet"]["title"],
                 "published": i["snippet"]["publishedAt"],
                 "url": f"https://www.youtube.com/watch?v={i['id']['videoId']}"}
                for i in data.get("items", []) if i["id"].get("videoId")]
    except Exception as e:
        print(f"  âš  YouTube API ã‚¨ãƒ©ãƒ¼: {e}")
        return []


def fetch_transcript(video_id):
    try:
        from youtube_transcript_api import YouTubeTranscriptApi
        for langs in [["ja"], ["en"], None]:
            try:
                if langs:
                    entries = YouTubeTranscriptApi.get_transcript(video_id, languages=langs)
                else:
                    entries = YouTubeTranscriptApi.get_transcript(video_id)
                text = " ".join([e.get("text", "") if isinstance(e, dict) else str(e) for e in entries])
                if text.strip():
                    return text[:8000]
            except Exception:
                continue
        return None
    except Exception as e:
        print(f"    âš  Transcriptå–å¾—å¤±æ•—: {e}")
        return None


def extract_sentiment_claude(text, channel_name, video_title, api_key):
    prompt = f"""ä»¥ä¸‹ã¯YouTubeã®æ ªå¼æŠ•è³‡ãƒãƒ£ãƒ³ãƒãƒ«ã€Œ{channel_name}ã€ã®å‹•ç”»ã€Œ{video_title}ã€ã®æ–‡å­—èµ·ã“ã—ã§ã™ã€‚

ã“ã®å‹•ç”»ã‹ã‚‰ä»¥ä¸‹ã®æƒ…å ±ã‚’JSONå½¢å¼ã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

1. topics: è©±é¡Œã«ãªã£ã¦ã„ã‚‹é …ç›®ã®ãƒªã‚¹ãƒˆã€‚å„é …ç›®ã«ä»¥ä¸‹ã‚’å«ã‚€ï¼š
   - topic: ãƒ†ãƒ¼ãƒåï¼ˆéŠ˜æŸ„åã€ã‚»ã‚¯ã‚¿ãƒ¼åã€çµŒæ¸ˆã‚¤ãƒ™ãƒ³ãƒˆåãªã©ï¼‰
   - category: "stock"/"sector"/"macro"/"event" ã®ã„ãšã‚Œã‹
   - sentiment: "bullish"/"bearish"/"neutral"/"hype"/"fear" ã®ã„ãšã‚Œã‹
   - confidence: 0.0ã€œ1.0
   - summary: ä¸€è¨€è¦ç´„ï¼ˆ30æ–‡å­—ä»¥å†…ï¼‰

2. overall_mood: å‹•ç”»å…¨ä½“ã®ãƒ ãƒ¼ãƒ‰ï¼ˆ"bullish"/"bearish"/"neutral"/"cautious"/"mixed"ï¼‰

3. key_quote: å°è±¡çš„ãªä¸€è¨€ï¼ˆ50æ–‡å­—ä»¥å†…ï¼‰

JSONã®ã¿ã‚’å‡ºåŠ›ã€‚ãƒãƒƒã‚¯ã‚¯ã‚©ãƒ¼ãƒˆä¸è¦ã€‚

--- æ–‡å­—èµ·ã“ã— ---
{text[:5000]}
"""
    body = json.dumps({
        "model": "claude-sonnet-4-20250514", "max_tokens": 1500,
        "messages": [{"role": "user", "content": prompt}],
    }).encode()
    req = urllib.request.Request(ANTHROPIC_API_URL, data=body, headers={
        "Content-Type": "application/json", "x-api-key": api_key, "anthropic-version": "2023-06-01",
    })
    try:
        with urllib.request.urlopen(req, timeout=60) as resp:
            result = json.loads(resp.read().decode())
        tc = result["content"][0]["text"].strip()
        if tc.startswith("```"):
            tc = re.sub(r"^```\w*\n?", "", tc)
            tc = re.sub(r"\n?```$", "", tc)
        return json.loads(tc)
    except Exception as e:
        print(f"    âš  Claude API ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def extract_sentiment_keywords(text, video_title):
    bullish = ["ä¸Šæ˜‡","è²·ã„","å¼·æ°—","æœŸå¾…","å¥½æ±ºç®—","ä¸ŠãŒã‚‹","ãƒãƒ£ãƒ³ã‚¹","æŠ¼ã—ç›®","åç™º","é«˜é…å½“","ä¸Šæ–¹ä¿®æ­£","æœ€é«˜å€¤","è²·ã„å¢—ã—"]
    bearish = ["ä¸‹è½","å£²ã‚Š","å¼±æ°—","æš´è½","ãƒªã‚¹ã‚¯","ä¸‹ãŒã‚‹","å±é™º","æåˆ‡","å¤©äº•","éç†±","ä¸‹æ–¹ä¿®æ­£","æ€¥è½","æš´è½"]
    patterns = [
        (r"æ—¥çµŒå¹³å‡|æ—¥çµŒ225|TOPIX|æ—¥çµŒ", "macro"), (r"NVDA|NVIDIA|ã‚¨ãƒŒãƒ“ãƒ‡ã‚£ã‚¢", "stock"),
        (r"åŠå°ä½“", "sector"), (r"AIéŠ˜æŸ„|AIé–¢é€£", "sector"), (r"SaaS", "sector"),
        (r"ãƒˆãƒ¨ã‚¿", "stock"), (r"ã‚½ãƒ‹ãƒ¼", "stock"), (r"ä»»å¤©å ‚", "stock"),
        (r"ä¿¡è¶ŠåŒ–å­¦", "stock"), (r"ã‚¤ãƒ“ãƒ‡ãƒ³", "stock"), (r"ã‚³ãƒ¼ã‚¨ãƒ¼ãƒ†ã‚¯ãƒ¢", "stock"),
        (r"S&P500|ãƒŠã‚¹ãƒ€ãƒƒã‚¯|ãƒ€ã‚¦", "macro"), (r"é…å½“|é«˜é…å½“", "sector"),
        (r"å††å®‰|å††é«˜|ãƒ‰ãƒ«å††", "macro"), (r"é‡‘åˆ©|FRB|æ—¥éŠ€", "macro"),
        (r"æ±ºç®—", "event"), (r"ãƒˆãƒ©ãƒ³ãƒ—|é–¢ç¨", "macro"),
        (r"éŠ€è¡Œ|ãƒ¡ã‚¬ãƒãƒ³ã‚¯", "sector"), (r"é˜²è¡›", "sector"), (r"ä¸å‹•ç”£|REIT", "sector"),
    ]
    topics, seen = [], set()
    for pat, cat in patterns:
        ms = re.findall(pat, text)
        if ms:
            w = ms[0]
            if w in seen: continue
            seen.add(w)
            idx = text.find(w)
            ctx = text[max(0,idx-200):idx+200]
            bu = sum(1 for b in bullish if b in ctx)
            be = sum(1 for b in bearish if b in ctx)
            s = "bullish" if bu > be else "bearish" if be > bu else "neutral"
            topics.append({"topic":w,"category":cat,"sentiment":s,"confidence":0.4,"summary":f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {w}"})
    bt = sum(1 for b in bullish if b in text)
    bt2 = sum(1 for b in bearish if b in text)
    mood = "bullish" if bt > bt2*1.3 else "bearish" if bt2 > bt*1.3 else "mixed"
    return {"topics": topics[:15], "overall_mood": mood, "key_quote": video_title[:50]}


def main():
    yt_key = os.environ.get("YOUTUBE_API_KEY", "")
    claude_key = os.environ.get("ANTHROPIC_API_KEY", "")
    if not yt_key:
        print("âŒ YOUTUBE_API_KEY ãŒæœªè¨­å®š"); sys.exit(1)

    use_claude = bool(claude_key)
    print(f"{'ğŸ¤– AIè¦ç´„ãƒ¢ãƒ¼ãƒ‰' if use_claude else 'ğŸ“ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºãƒ¢ãƒ¼ãƒ‰'}")

    today = datetime.now().strftime("%Y-%m-%d")
    SENTIMENT_DIR.mkdir(exist_ok=True)

    all_entries, video_count, channel_results = [], 0, {}

    print(f"\n{'='*50}")
    print(f"ğŸ“¡ MARKET SENTIMENT COLLECTOR â€” {today}")
    print(f"{'='*50}")

    for handle, ch_name in CHANNELS.items():
        print(f"\nğŸ“º {ch_name} ({handle})")
        ch_id = resolve_handle(yt_key, handle)
        if not ch_id:
            print("  â†’ ãƒãƒ£ãƒ³ãƒãƒ«IDå–å¾—å¤±æ•—"); continue
        print(f"  â†’ ID: {ch_id}")

        videos = fetch_latest_videos(yt_key, ch_id, max_results=3)
        if not videos:
            print(f"  â†’ éå»{MAX_AGE_DAYS}æ—¥ã®å‹•ç”»ãªã—"); continue
        print(f"  â†’ {len(videos)}æœ¬ç™ºè¦‹")

        ch_bull, ch_bear = 0, 0
        for v in videos:
            print(f"  ğŸ¬ {v['title'][:55]}...")
            video_count += 1
            transcript = fetch_transcript(v["video_id"])
            if not transcript:
                print("    â†’ å­—å¹•ãªã—ã€ã‚¹ã‚­ãƒƒãƒ—"); continue
            print(f"    â†’ å­—å¹•OKï¼ˆ{len(transcript)}æ–‡å­—ï¼‰")

            result = None
            if use_claude:
                result = extract_sentiment_claude(transcript, ch_name, v["title"], claude_key)
            if not result:
                result = extract_sentiment_keywords(transcript, v["title"])

            if result and result.get("topics"):
                for topic in result["topics"]:
                    e = {"source":"youtube","channel":ch_name,"video_title":v["title"][:80],
                         "video_url":v["url"],"topic":topic.get("topic",""),
                         "category":topic.get("category","macro"),
                         "sentiment":topic.get("sentiment","neutral"),
                         "confidence":topic.get("confidence",0.5),
                         "summary":topic.get("summary","")}
                    all_entries.append(e)
                    if e["sentiment"] in ("bullish","hype"): ch_bull += 1
                    elif e["sentiment"] in ("bearish","fear"): ch_bear += 1
                print(f"    â†’ {len(result['topics'])}ãƒˆãƒ”ãƒƒã‚¯ / ãƒ ãƒ¼ãƒ‰: {result.get('overall_mood','?')}")
                if result.get("key_quote"):
                    print(f"    ğŸ’¬ {result['key_quote']}")

        channel_results[ch_name] = {"bull": ch_bull, "bear": ch_bear}

    # é›†è¨ˆ
    tc = {}
    for e in all_entries:
        t = e["topic"]
        if t not in tc: tc[t] = {"count":0,"sentiments":[],"sources":set()}
        tc[t]["count"] += 1; tc[t]["sentiments"].append(e["sentiment"]); tc[t]["sources"].add(e["channel"])

    by_topic = {t: {"count":d["count"],"sentiment":Counter(d["sentiments"]).most_common(1)[0][0],
                     "sources":list(d["sources"])} for t, d in tc.items()}
    hot_words = [t for t,_ in sorted(tc.items(), key=lambda x:-x[1]["count"])][:15]

    output = {"date":today,"collected_at":datetime.now().strftime("%Y-%m-%d %H:%M"),
              "mode":"claude" if use_claude else "keywords",
              "channels_checked":len(CHANNELS),"videos_processed":video_count,
              "entry_count":len(all_entries),"entries":all_entries,
              "summary":{"by_channel":channel_results,"by_topic":by_topic,"hot_words":hot_words}}

    out_path = SENTIMENT_DIR / f"{today}.json"
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f"\n{'='*50}")
    print(f"âœ… å®Œäº†: {len(all_entries)}ä»¶åé›† / {video_count}æœ¬å‡¦ç†")
    if hot_words: print(f"ğŸ”¥ ãƒ›ãƒƒãƒˆãƒ¯ãƒ¼ãƒ‰: {', '.join(hot_words[:5])}")
    for ch, d in channel_results.items():
        print(f"  {ch}: {'ğŸŸ¢'*d['bull']}{'ğŸ”´'*d['bear']} ({d['bull']}/{d['bear']})")
    print(f"{'='*50}")

    # Discord
    wh = os.environ.get("DISCORD_WEBHOOK_URL","")
    if wh and all_entries:
        try:
            bull = sum(1 for e in all_entries if e["sentiment"] in ("bullish","hype"))
            bear = sum(1 for e in all_entries if e["sentiment"] in ("bearish","fear"))
            msg = f"ğŸ“¡ **ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåé›†** ({today})\nå‹•ç”»{video_count}æœ¬/{len(all_entries)}ä»¶\nå¼·æ°—{bull}/å¼±æ°—{bear}\nğŸ”¥ {', '.join(hot_words[:5])}"
            for ch, d in channel_results.items():
                msg += f"\n  {ch}: ğŸŸ¢{d['bull']} ğŸ”´{d['bear']}"
            body = json.dumps({"content": msg}).encode()
            urllib.request.urlopen(urllib.request.Request(wh, data=body,
                headers={"Content-Type":"application/json"}), timeout=10)
            print("ğŸ“¢ Discordé€šçŸ¥é€ä¿¡")
        except Exception as e:
            print(f"âš  Discord: {e}")


if __name__ == "__main__":
    main()
