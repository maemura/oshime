#!/usr/bin/env python3
"""
validate.py â€” æ¨è–¦éŠ˜æŸ„ã®äº‹å¾Œæ¤œè¨¼ + é…ç‚¹æœ€é©åŒ–
==============================================
æ¯æœã®ã‚¹ã‚­ãƒ£ãƒ³å¾Œã«è‡ªå‹•å®Ÿè¡Œã€‚
1. 5æ—¥å‰ã®æ¨è–¦TOP5ã®æ ªä¾¡ã‚’æ¤œè¨¼
2. çµæœã‚’ history/ ã«è¿½è¨˜
3. 30æ—¥åˆ†æºœã¾ã£ãŸã‚‰é…ç‚¹æœ‰åŠ¹æ€§ã‚’åˆ†æ
4. é€±æ¬¡ã§é…ç‚¹èª¿æ•´æ¡ˆã‚’å‡ºåŠ› â†’ weights.json
"""

import json, os, glob, math
from datetime import datetime, timedelta

HISTORY_DIR = "history"
WEIGHTS_FILE = "weights.json"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé…ç‚¹ï¼ˆv3æ‰‹å‹•è¨­å®šï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
DEFAULT_WEIGHTS = {
    "dividend":       20,   # é…å½“åˆ©å›ã‚Š max
    "market_cap":     10,   # æ™‚ä¾¡ç·é¡ max
    "div_growth":     10,   # é€£ç¶šå¢—é… max
    "dip_zscore":     15,   # è‡ªåˆ†æ¯”æŠ¼ã—ç›® max
    "pbr":             5,   # PBR max
    "ret5_vs_sector": 20,   # å€‹åˆ¥vsã‚»ã‚¯ã‚¿ãƒ¼å·®åˆ† max
    "ret5":           10,   # å€‹åˆ¥5æ—¥ä¸‹è½ max
    "ret10":           5,   # 10æ—¥ãƒªã‚¿ãƒ¼ãƒ³ max
    "stable_bonus":    5,   # å®‰å®šæ ªãƒœãƒ¼ãƒŠã‚¹ max
    "sector_penalty": -5,   # ã‚»ã‚¯ã‚¿ãƒ¼ä¸‹è½ãƒšãƒŠãƒ«ãƒ†ã‚£
}

def load_weights():
    """ç¾åœ¨ã®é…ç‚¹ã‚’èª­ã¿è¾¼ã¿"""
    if os.path.exists(WEIGHTS_FILE):
        with open(WEIGHTS_FILE, encoding="utf-8") as f:
            return json.load(f)
    return DEFAULT_WEIGHTS.copy()

def save_weights(w):
    with open(WEIGHTS_FILE, "w", encoding="utf-8") as f:
        json.dump(w, f, ensure_ascii=False, indent=2)

def get_history_file(date_str):
    path = os.path.join(HISTORY_DIR, f"{date_str}.json")
    if os.path.exists(path):
        with open(path, encoding="utf-8") as f:
            return json.load(f)
    return None

def get_current_prices(codes):
    """yfinanceã§ç¾åœ¨ä¾¡æ ¼ã‚’å–å¾—"""
    try:
        import yfinance as yf
        tickers = [f"{c}.T" for c in codes]
        data = yf.download(tickers, period="5d", progress=False)
        prices = {}
        if len(tickers) == 1:
            close = data["Close"]
            if len(close) > 0:
                prices[codes[0]] = float(close.iloc[-1])
        else:
            for code, ticker in zip(codes, tickers):
                try:
                    col = data["Close"][ticker]
                    if len(col) > 0:
                        prices[code] = float(col.iloc[-1])
                except:
                    pass
        return prices
    except Exception as e:
        print(f"  âš  ä¾¡æ ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return {}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 1: 5æ—¥å‰ã®æ¨è–¦ã‚’æ¤œè¨¼
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def validate_past_recommendations():
    """5æ—¥å‰ã®TOP5ã‚’æ¤œè¨¼ã—ã¦çµæœã‚’è¨˜éŒ²"""
    today = datetime.now()
    
    # 5å–¶æ¥­æ—¥å‰ã‚’æ¢ã™ï¼ˆåœŸæ—¥ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    check_dates = []
    d = today - timedelta(days=1)
    while len(check_dates) < 10:
        d -= timedelta(days=1)
        if d.weekday() < 5:  # æœˆã€œé‡‘
            check_dates.append(d.strftime("%Y-%m-%d"))
    
    validated = False
    for target_date in check_dates[4:8]:  # 5ã€œ8å–¶æ¥­æ—¥å‰ã‚’ãƒã‚§ãƒƒã‚¯
        hist = get_history_file(target_date)
        if not hist:
            continue
        if hist.get("validated"):
            continue  # æ—¢ã«æ¤œè¨¼æ¸ˆã¿
        
        top5 = hist.get("top5", [])
        if not top5:
            continue
        
        codes = [s["code"] for s in top5]
        current_prices = get_current_prices(codes)
        
        if not current_prices:
            continue
        
        # å„éŠ˜æŸ„ã®5æ—¥å¾Œãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—
        results = []
        for s in top5:
            code = s["code"]
            old_price = s.get("price", 0)
            new_price = current_prices.get(code, 0)
            if old_price > 0 and new_price > 0:
                ret = round((new_price / old_price - 1) * 100, 2)
                results.append({
                    "code": code,
                    "name": s.get("name", ""),
                    "score": s.get("score", 0),
                    "price_then": old_price,
                    "price_now": new_price,
                    "return_5d": ret,
                })
        
        if not results:
            continue
        
        # å¸‚å ´å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆæ—¥çµŒ225ã®proxyï¼‰
        nikkei_prices = get_current_prices(["998407"])  # æ—¥çµŒå¹³å‡ã®yfinanceã‚³ãƒ¼ãƒ‰
        market_ret = 0
        nikkei_then = hist.get("market", {}).get("nikkei_price", 0)
        # å¸‚å ´ãƒªã‚¿ãƒ¼ãƒ³ã¯è¿‘ä¼¼ï¼ˆæ­£ç¢ºã«ã¯indexä½¿ã†ï¼‰
        
        # Î±è¨ˆç®—
        avg_ret = sum(r["return_5d"] for r in results) / len(results) if results else 0
        alpha = round(avg_ret - market_ret, 2)
        hit_rate = round(sum(1 for r in results if r["return_5d"] > market_ret) / len(results) * 100, 1) if results else 0
        
        # çµæœã‚’å±¥æ­´ã«è¿½è¨˜
        validation = {
            "validated": True,
            "validated_at": today.strftime("%Y-%m-%d"),
            "results": results,
            "avg_return_5d": round(avg_ret, 2),
            "market_return_5d": market_ret,
            "alpha": alpha,
            "hit_rate": hit_rate,
        }
        hist.update(validation)
        
        # ä¿å­˜
        hist_path = os.path.join(HISTORY_DIR, f"{target_date}.json")
        with open(hist_path, "w", encoding="utf-8") as f:
            json.dump(hist, f, ensure_ascii=False, indent=2)
        
        print(f"  âœ… {target_date}ã®æ¨è–¦ã‚’æ¤œè¨¼:")
        for r in results:
            mark = "âœ…" if r["return_5d"] > market_ret else "âŒ"
            print(f"    {mark} {r['name']} ({r['code']}): {r['return_5d']:+.1f}%")
        print(f"    ğŸ“Š å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³: {avg_ret:+.1f}%  Î±: {alpha:+.1f}%  çš„ä¸­ç‡: {hit_rate}%")
        validated = True
        break  # 1æ—¥åˆ†ã ã‘æ¤œè¨¼
    
    if not validated:
        print("  ğŸ“­ æ¤œè¨¼å¯¾è±¡ãªã—ï¼ˆ5æ—¥å‰ã®å±¥æ­´ãŒã¾ã ãªã„ï¼‰")
    
    return validated

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 2: é…ç‚¹ã®æœ‰åŠ¹æ€§åˆ†æ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def analyze_weights():
    """æ¤œè¨¼æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å„æŒ‡æ¨™ã®æœ‰åŠ¹æ€§ã‚’åˆ†æ"""
    files = sorted(glob.glob(os.path.join(HISTORY_DIR, "*.json")))
    
    validated_data = []
    for f in files:
        with open(f, encoding="utf-8") as fh:
            d = json.load(fh)
        if d.get("validated") and d.get("results"):
            validated_data.append(d)
    
    if len(validated_data) < 5:
        print(f"  ğŸ“Š æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ {len(validated_data)}ä»¶ï¼ˆæœ€ä½5ä»¶å¿…è¦ã€ã¾ã è¶³ã‚Šãªã„ï¼‰")
        return None
    
    print(f"  ğŸ“Š æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ {len(validated_data)}ä»¶ã§åˆ†æé–‹å§‹")
    
    # å„æŒ‡æ¨™ã¨5æ—¥å¾Œãƒªã‚¿ãƒ¼ãƒ³ã®ç›¸é–¢ã‚’åˆ†æ
    # TOP5ã®ä¸­ã§ã€Œå½“ãŸã£ãŸéŠ˜æŸ„ã€ã¨ã€Œå¤–ã‚ŒãŸéŠ˜æŸ„ã€ã®æŒ‡æ¨™å€¤ã‚’æ¯”è¼ƒ
    indicator_effectiveness = {}
    
    indicators = ["dividend", "dip_zscore", "ret5", "ret5_vs_sector", "div_growth_years"]
    
    for ind in indicators:
        hit_vals = []
        miss_vals = []
        for d in validated_data:
            top5 = d.get("top5", [])
            results = d.get("results", [])
            market_ret = d.get("market_return_5d", 0)
            
            result_map = {r["code"]: r for r in results}
            for s in top5:
                code = s["code"]
                if code in result_map:
                    val = s.get(ind, 0)
                    ret = result_map[code]["return_5d"]
                    if ret > market_ret:
                        hit_vals.append(val)
                    else:
                        miss_vals.append(val)
        
        if hit_vals and miss_vals:
            hit_avg = sum(hit_vals) / len(hit_vals)
            miss_avg = sum(miss_vals) / len(miss_vals)
            diff = round(hit_avg - miss_avg, 3)
            indicator_effectiveness[ind] = {
                "hit_avg": round(hit_avg, 3),
                "miss_avg": round(miss_avg, 3),
                "diff": diff,
                "sample_size": len(hit_vals) + len(miss_vals),
            }
            direction = "â†‘åŠ¹æœã‚ã‚Š" if abs(diff) > 0.5 else "â†’åŠ¹æœè–„ã„"
            print(f"    {ind}: çš„ä¸­å¹³å‡={hit_avg:.2f} å¤–ã‚Œå¹³å‡={miss_avg:.2f} å·®={diff:.2f} {direction}")
    
    return indicator_effectiveness

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 3: é…ç‚¹ã®è‡ªå‹•èª¿æ•´
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def optimize_weights():
    """æ¤œè¨¼çµæœã«åŸºã¥ã„ã¦é…ç‚¹ã‚’å¾®èª¿æ•´ï¼ˆÂ±3ptä»¥å†…ï¼‰"""
    effectiveness = analyze_weights()
    if not effectiveness:
        return
    
    current = load_weights()
    updated = current.copy()
    changes = []
    
    # æŒ‡æ¨™å â†’ é…ç‚¹ã‚­ãƒ¼ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    ind_to_key = {
        "dividend": "dividend",
        "dip_zscore": "dip_zscore",
        "ret5": "ret5",
        "ret5_vs_sector": "ret5_vs_sector",
        "div_growth_years": "div_growth",
    }
    
    for ind, stats in effectiveness.items():
        key = ind_to_key.get(ind)
        if not key or key not in updated:
            continue
        
        diff = stats["diff"]
        sample = stats["sample_size"]
        
        if sample < 10:
            continue  # ã‚µãƒ³ãƒ—ãƒ«ä¸è¶³
        
        # åŠ¹æœãŒé«˜ã„æŒ‡æ¨™ã¯+1ã€œ+3ptã€åŠ¹æœãŒä½ã„æŒ‡æ¨™ã¯-1ã€œ-3pt
        if abs(diff) > 2.0:
            adj = 3 if diff > 0 else -3
        elif abs(diff) > 1.0:
            adj = 2 if diff > 0 else -2
        elif abs(diff) > 0.5:
            adj = 1 if diff > 0 else -1
        else:
            adj = 0
        
        # retç³»ã¯é€†ï¼ˆãƒã‚¤ãƒŠã‚¹ãŒè‰¯ã„ï¼‰
        if ind in ["ret5", "ret5_vs_sector", "dip_zscore"]:
            adj = -adj
        
        if adj != 0:
            old_val = updated[key]
            new_val = max(0, min(25, old_val + adj))  # 0ã€œ25ã®ç¯„å›²
            if new_val != old_val:
                updated[key] = new_val
                changes.append(f"  {key}: {old_val} â†’ {new_val} ({'+' if adj>0 else ''}{adj})")
    
    if changes:
        # åˆè¨ˆãŒ100ã«ãªã‚‹ã‚ˆã†ã«æ­£è¦åŒ–
        total = sum(v for k, v in updated.items() if v > 0)
        
        save_weights(updated)
        print(f"\n  ğŸ”„ é…ç‚¹æ›´æ–°:")
        for c in changes:
            print(c)
        print(f"  ğŸ“ {WEIGHTS_FILE} ã«ä¿å­˜")
    else:
        print(f"\n  âœ… é…ç‚¹å¤‰æ›´ãªã—ï¼ˆç¾çŠ¶ç¶­æŒï¼‰")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 4: æˆç¸¾ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def generate_report():
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ã®é€±æ¬¡æˆç¸¾ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    files = sorted(glob.glob(os.path.join(HISTORY_DIR, "*.json")))
    
    validated = []
    for f in files:
        with open(f, encoding="utf-8") as fh:
            d = json.load(fh)
        if d.get("validated"):
            validated.append(d)
    
    if not validated:
        return None
    
    # ç›´è¿‘7æ—¥ã®æ¤œè¨¼çµæœ
    recent = validated[-5:]
    
    all_results = []
    for d in recent:
        for r in d.get("results", []):
            all_results.append(r)
    
    if not all_results:
        return None
    
    total_alpha = sum(d.get("alpha", 0) for d in recent)
    avg_hit_rate = sum(d.get("hit_rate", 0) for d in recent) / len(recent) if recent else 0
    avg_return = sum(r["return_5d"] for r in all_results) / len(all_results) if all_results else 0
    
    # ãƒ™ã‚¹ãƒˆ/ãƒ¯ãƒ¼ã‚¹ãƒˆ
    best = max(all_results, key=lambda x: x["return_5d"])
    worst = min(all_results, key=lambda x: x["return_5d"])
    
    report = {
        "period": f"{recent[0]['date']} ã€œ {recent[-1]['date']}",
        "days_validated": len(recent),
        "total_stocks": len(all_results),
        "avg_return": round(avg_return, 2),
        "total_alpha": round(total_alpha, 2),
        "avg_hit_rate": round(avg_hit_rate, 1),
        "best": {"name": best["name"], "return": best["return_5d"]},
        "worst": {"name": worst["name"], "return": worst["return_5d"]},
    }
    
    report_path = os.path.join(HISTORY_DIR, "latest_report.json")
    with open(report_path, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"\n  ğŸ“Š æˆç¸¾ãƒ¬ãƒãƒ¼ãƒˆ ({report['period']})")
    print(f"    æ¤œè¨¼æ—¥æ•°: {report['days_validated']}æ—¥  éŠ˜æŸ„æ•°: {report['total_stocks']}")
    print(f"    å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³: {report['avg_return']:+.1f}%")
    print(f"    ç´¯è¨ˆÎ±: {report['total_alpha']:+.1f}%")
    print(f"    çš„ä¸­ç‡: {report['avg_hit_rate']:.0f}%")
    print(f"    âœ… ãƒ™ã‚¹ãƒˆ: {report['best']['name']} {report['best']['return']:+.1f}%")
    print(f"    âŒ ãƒ¯ãƒ¼ã‚¹ãƒˆ: {report['worst']['name']} {report['worst']['return']:+.1f}%")
    
    return report

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def main():
    print("\n" + "=" * 50)
    print("  ğŸ“‹ æ¨è–¦æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 50)
    
    # Step 1: éå»ã®æ¨è–¦ã‚’æ¤œè¨¼
    print("\nğŸ” Step 1: éå»ã®æ¨è–¦ã‚’æ¤œè¨¼")
    validate_past_recommendations()
    
    # Step 2: æˆç¸¾ãƒ¬ãƒãƒ¼ãƒˆ
    print("\nğŸ“Š Step 2: æˆç¸¾ãƒ¬ãƒãƒ¼ãƒˆ")
    report = generate_report()
    
    # Step 3: é…ç‚¹æœ€é©åŒ–ï¼ˆæ—¥æ›œã®ã¿ã€ã¾ãŸã¯æ‰‹å‹•ï¼‰
    today = datetime.now()
    if today.weekday() == 6 or os.environ.get("FORCE_OPTIMIZE"):
        print("\nğŸ”„ Step 3: é…ç‚¹æœ€é©åŒ–ï¼ˆé€±æ¬¡ï¼‰")
        optimize_weights()
    else:
        print(f"\nâ­ Step 3: é…ç‚¹æœ€é©åŒ–ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ—¥æ›œã«å®Ÿè¡Œï¼‰")
    
    print("\n" + "=" * 50)

if __name__ == "__main__":
    main()
